# 1. [실습] Control Plane 로깅 확인
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/09f9debf-d02d-4f45-859c-f4071b9d2c2e)

## 1.1 Control Plane 로깅 활성화
1) 컨트롤 플레인 로깅을 활성화
   - 컨트롤 플레인의 대상 요소를 선택, 로깅 활성화를 수행하면 -> 아마존 클라우드 워치에 로그 그룹이 자동으로 생성
   - 로그 그룹 내에는 로그 스트림이 존재

2) 컨트롤 플레인 로깅 대상의 5가지 유형 (기본 설정상 로깅은 비활성화 상태 -> 대상을 선택해서 로깅 기능을 활성화 필)
   - API 서버
   - Authenticator
   - 스케줄러
   - 감사
   - 컨트롤러 관리
  
3) 클라우드 워치에 로그 그룹이 자동으로 생성되고 -> 로그 스트림이 생성
   - 앞에 접두어를 통해 어떠한 컨트롤 플레인 대상의 로그인지 알 수 있음.

## 1.2 Control Plane 로그 확인
1) AWS CLI를 통해 확인 또는 클라우드 워치를 통해 로그 스트림을 보고 로그 인사이트에서 가시성 있게 로그를 확인 가능.

## 1.3 Control Plane 로깅 비활성화
   
---

# 1. Control Plane 로깅 확인
- 실습은 4장 Amazon EKS 원클릭 배포 환경에서 진행
- 인프라 배포를 진행하지 않은 경우 링크를 통해 배포 후 복귀
- 새롭게 인프라를 배포하면 아래 기본 설정 명령을 입력 후 진행

## 기본 설정 명령어

### Default 네임 스페이스 변경
```
kubectl ns default
```

### 워커 노드의 IP 변수 선언
```
N1=$(kubectl get node --label-columns=topology.kubernetes.io/zone --selector=topology.kubernetes.io/zone=ap-northeast-2a -o jsonpath={.items[0].status.addresses[0].address})

N2=$(kubectl get node --label-columns=topology.kubernetes.io/zone --selector=topology.kubernetes.io/zone=ap-northeast-2b -o jsonpath={.items[0].status.addresses[0].address})

N3=$(kubectl get node --label-columns=topology.kubernetes.io/zone --selector=topology.kubernetes.io/zone=ap-northeast-2c -o jsonpath={.items[0].status.addresses[0].address})

echo "export N1=$N1" >> /etc/profile

echo "export N2=$N2" >> /etc/profile

echo "export N3=$N3" >> /etc/profile
```

### 노드에 SSH 접근
```
for node in $N1 $N2 $N3; do ssh ec2-user@$node hostname; done
```

### AWS Load Balancer Controller 설치
```
helm repo add eks https://aws.github.io/eks-charts

helm repo update

helm install aws-load-balancer-controller eks/aws-load-balancer-controller -n kube-system --set clusterName=$CLUSTER_NAME \
  --set serviceAccount.create=false \
  --set serviceAccount.name=aws-load-balancer-controller
```

### ExternalDNS 설치
```
// 자신의 도메인 주소로 설정
MyDomain=<자신의 도메인>

MyDnsHostedZoneId=$(aws route53 list-hosted-zones-by-name --dns-name "${MyDomain}." --query "HostedZones[0].Id" --output text)

echo $MyDomain, $MyDnsHostedZoneId

curl -s -O https://raw.githubusercontent.com/cloudneta/cnaeblab/master/_data/externaldns.yaml

MyDomain=$MyDomain MyDnsHostedZoneId=$MyDnsHostedZoneId envsubst < externaldns.yaml | kubectl apply -f -
```

### kube-ops-view 설치
```
helm repo add geek-cookbook https://geek-cookbook.github.io/charts/

helm install kube-ops-view geek-cookbook/kube-ops-view --version 1.2.2 --set env.TZ="Asia/Seoul" --namespace kube-system

kubectl patch svc -n kube-system kube-ops-view -p '{"spec":{"type":"LoadBalancer"}}'

kubectl annotate service kube-ops-view -n kube-system "external-dns.alpha.kubernetes.io/hostname=kubeopsview.$MyDomain"

echo -e "Kube Ops View URL = http://kubeopsview.$MyDomain:8080/#scale=1.5"
```

### StorageClass 생성
```
cat <<EOT > gp3-sc.yaml
kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: gp3
allowVolumeExpansion: true
provisioner: ebs.csi.aws.com
volumeBindingMode: WaitForFirstConsumer
parameters:
  type: gp3
  allowAutoIOPSPerGBIncrease: 'true'
  encrypted: 'true'
EOT

kubectl apply -f gp3-sc.yaml
```

### ACM 인증서 변수 선언
```
CERT_ARN=`aws acm list-certificates --query 'CertificateSummaryList[].CertificateArn[]' --output text`
```

---

## 1.1. Control Plane 로깅 활성화
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/4f1ecfcf-e64c-4e19-82f0-4753eef910ec)
1) 최초 비활성화 상태 확인.
   - AWS Console에서 로깅 활성화 가능.

### 1.1.1 Amazon EKS Control Plane 명령어를 통한 로깅 활성화
```
// Amazon EKS Control Plane 로깅 활성화 설정
aws eks update-cluster-config --region $AWS_DEFAULT_REGION --name $CLUSTER_NAME \
  --logging '{"clusterLogging":[{"types":["api","audit","authenticator","controllerManager","scheduler"],"enabled":true}]}'
```

![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/cdc1735e-7101-43b3-ad61-3e2282a5ea74)
1) 로깅 활성화

![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/f5f76799-86cb-4de8-b7f1-2c134b398243)
1) AWS Console에서 활성화 확인.

### 1.1.2 로그 그룹 및 로그 스트림 확인
```
// CloudWatch의 로그 그룹 생성 확인
aws logs describe-log-groups | jq
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/c0b58725-5dde-4c0d-9a6e-c74f84d4811e)
1) 고정된 형태의 Cloudwatch 이름 구조에 세 번째 영역에 자신의 EKS 클러스터 이름으로 생성 -> /aws/eks/{클러스터 이름}/cluster
   
```
// 로그 그룹에 구성된 로그 스트림 확인
aws logs describe-log-streams \
  --log-group-name /aws/eks/${CLUSTER_NAME}/cluster | grep logStreamName
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/f9c0cdee-165c-471a-a31d-b2575ecac407)


## 1.2. Control Plane 로그 확인


### 1.2.1 awscli로 Control Plane 로그 확인
```
// 10분 동안 Control Plane 로그 확인(more 옵션)
aws logs tail /aws/eks/$CLUSTER_NAME/cluster | more
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/eb7ba053-29d5-4247-a9e5-2aeb43673318)

```
// 신규 로그 바로 출력
aws logs tail /aws/eks/$CLUSTER_NAME/cluster --follow
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/d54d32fc-3ff8-481c-a6ce-24e1d735a27d)

```
//로그 스트림 대상 지정 (kube-controller-mananger)
aws logs tail /aws/eks/$CLUSTER_NAME/cluster --log-stream-name-prefix kube-controller-manager --follow

// 신규 터미널 생성 후 coreDNS 수량 조정
kubectl scale deployment -n kube-system coredns --replicas=1
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/d701cc1f-099d-43ba-9bfc-cc3da5451cec)

```
kubectl scale deployment -n kube-system coredns --replicas=2
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/4d939b19-b420-4e5c-9bff-aab38b5d0bb3)

- 관리 콘솔에서 CloudWatch 서비스에 로그 영역에서 Logs Insights 메뉴로 진입
- Select up to 50 log groups에 생성한 로그 그룹을 선택 후 다음 작업을 수행
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/afe7b9ac-2a64-4cca-af56-7dc5ae2b5683)
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/27a77afb-2cfb-45e4-803d-6626f5d08a57)
1) 위에서 kubectl scale 명령어로 coredns의 replicas 갯수를 변경한 것을 Cloudwatch 로그에서 확인 가능.


### 1.2.2 CloudWatch 로그 인사이트에서 쿼리하기

![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/9d53730a-745d-4b73-9d0a-1dda4c1395bb)
1) 로그인사이트 쿼리를 실행하려면 먼저 로그그룹을 선택
2) 기본적으로 출력되고 있는 쿼리를 실행
3) 쿼리출력 : 모든 로그 스트림에 대해 최근 타임스탬프 순으로 정렬하고 20개만 나열결과 확인. 

```
// kube-apiserver-audit 로그에서 UserAgent 정렬 후 카운트 값
fields userAgent, requestURI, @timestamp, @message
| filter @logStream ~= "kube-apiserver-audit"
| stats count(userAgent) as count by userAgent
| sort count desc
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/57eab2ad-98b7-45d7-818b-48f9f08ad57f)

```
// kube-apiserver 로그에서 timestamp로 정렬
fields @timestamp, @message
| filter @logStream ~= "kube-apiserver"
| sort @timestamp desc
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/cd829e3c-c237-448d-ac4a-32050348e5f2)
1) Cloudwatch의 컨트롤 플레인 로그 정보를 보관 -> 로그 인사이트에서 쿼리를 수행하고 필요한 정보만 확인 가능.
2) 
```
// authenticator 로그에서 timestamp로 정렬
fields @timestamp, @message
| filter @logStream ~= "authenticator"
| sort @timestamp desc
```


## 1.3. Control Plane 로깅 비활성화


## 1.3.1 Control Plane 로깅 비활성화
```
// EKS Control Plane 로깅 비활성화
eksctl utils update-cluster-logging \
  --cluster $CLUSTER_NAME \
  --region $AWS_DEFAULT_REGION \
  --disable-types all \
  --approve
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/c6ba4e11-b83b-4384-8aae-bc0bbbaaa9d3)

```
// Control Plane 로그 그룹 삭제
aws logs delete-log-group --log-group-name /aws/eks/$CLUSTER_NAME/cluster
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/aeb60e62-37da-47db-9cd3-e7e342efec2b)
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/b48700e3-fa9b-48b1-86cc-2c1224822bbd)
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/bc4e0747-dcc0-4580-b829-5587029a75e2)






















