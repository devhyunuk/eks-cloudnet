# 3. [실습] FluentBit를 활용한 중앙 집중형 로깅 확인

- 노드 자체 로그와 Data Plane 로그 확인은 EKS에서 지원하지 않아 별도의 도구로 수집해야 함.
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/1656628f-f10c-4204-83db-ff5af8342df9)
1) 로깅 대상으로 노드 자체의 로깅과 데이터 플레인 로깅이 있음
2) EKS 자체 환경에서 로그 확인 작업을 지원하지 않아 별도로 해당 로그를 수집하는 도구를 설치해야 함.
3) AWS 공신문서에서 제안하는 Fluentbit 설치
4) Fluentbit는 3가지 유형의 로그 정보를 수집
   - 어플리케이션 로그 : 컨테이너 로그 정보를 수집
     - 수집을 위한 로그 소스 : /var/log/containers 의 경로를 참조해서 수집
   - 호스트 로그 : 노드 자체의 인스턴스에 대한 로그 정보를 수집
     - 수집을 위한 로그 소스 : /var/log/dmesg, Secure, messages 의 경로를 참조해서 수집
   - 데이터 플레인 로그 : EKS 클러스터의 데이터 플레인 영역에 로그 정보를 수집
     - 수집을 위한 로그 소스 : /var/log/journal 의 경로를 참조해서 수집
     - kubelet이나 kubeprox이나 컨테이너 런타임에 대한 로깅을 수행
    
5) Fluentbit가 대상 로그를 수집하는 원리
   - Fluentbit가 위 대상 로그의 소스 경로를 HostPath로 지정
   - HostPath로 지정해서 Fluentbit는 해당 경로를 참조해서 사용
  
6) Fluentbit 구조 형태
   - Input : 로그 소스의 HostPath를 지정하는 영역
   - Filter : Filter 형식 지정
   - Output : Output은 수집한 로그를 전달할 로깅 시스템 대상을 의미.  EKS 환경에서 Output 대상은 -> CloudWatch 서비스

![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/d0157b20-4161-412b-bedd-21b5337b1555)
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/0ba6e9e0-b1f9-4937-b444-d0f5d481209e)
7) 다수의 노드가 구성된 환경에서 로깅을 수행하기 위해 플루언트 비트를 설치
   - 각 노드마다 플루언트 비트를 데몬셋 형태로 설치하고 로그 정보를 수집 (노드의 로그 소스를 호스트 패스로 지정해서 참조)
   - 어플리케이션 로그와 호스트 로그와 데이터 플레인 로그를 수집
   - Fluent Bit를 설치하면 CloudWatch에서 로그 유형별로 로그 그룹을 생성
   - Fluent Bit는 아웃풋에 정의된 클라우드와치의 로그 그룹으로 수집한 로그를 전달.
   - Fluent Bit를 활용해 중앙 집중형 로깅 시스템을 구성 가능.

---

![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/4e163429-8a70-4f59-b1f9-0d37e281c25a)

# 3. FluentBit를 활용한 중앙 집중형 로깅 확인


## 3.1. 노드에서 로그 소스 확인
- 어플리케이션 로그 -> Host 로그 -> 데이터 플레인 로그 순으로 확

### 3.1.1 Application 로그 소스
```
// application 로그 소스 확인
for node in $N1 $N2 $N3; do echo ">>>>> $node <<<<<"; \
ssh ec2-user@$node sudo tree /var/log/containers; echo; done
```
1) 어플리케이션 로그 소스는 /var/log/containers 경로를 참조 -> 해당 경로에서 심벌리 링크로 /var/log/pods 경로를 연결
2) for문을 통해 n1, n2, n3 순서로 /var/log/containers의 트리 정보를 확인

![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/40fcb2f4-505b-4c94-b472-48e314d38758)
1) node1,2,3에 위치한 컨테이너 로그 정보를 /var/log/containers 단일 경로에 보관
2) 그리고 각각의 로그는 심볼릭 링크로 /var/log/pods에 위치한 로그 파일과 연결

```
for node in $N1 $N2 $N3; do echo ">>>>> $node <<<<<"; \
ssh ec2-user@$node sudo tree /var/log/pods; echo; done
```
1) /var/log/pods의 트리 정보를 확인

![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/ae98bc9b-97fb-4c98-b71a-b36c86d9fab7)
1) 마찬가지로 node1,2,3에 컨테이너별 디렉토리를 생성하고 로그 파일을 저장


### 3.1.2 Host 로그 소스 (노드 자체의 로그 정보인 Host 로그를 확인)
```
// host 로그 소스 (Logs from /var/log/dmesg, /var/log/secure, and /var/log/messages), 노드(호스트) 로그
for node in $N1 $N2 $N3; do echo ">>>>> $node <<<<<"; \
ssh ec2-user@$node sudo tree /var/log/ -L 1; echo; done
```
1) Host 로그가 위치하는 소스 경로는 /var/log에 존재하는 다수의 하위 경로에서 /dmesg, /secure/ message 경로.
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/ad9a662e-d85e-4d10-ad79-26880408e848)

```
// 노드 1에 dmesg, secure, messages 로그 확인
for log in dmesg secure messages; do echo ">>>>> Node1: /var/log/$log <<<<<"; \
ssh ec2-user@$N1 sudo tail /var/log/$log; echo; done
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/a6d1e670-63e5-4fb2-b6b8-038e28b93dea)
1) dmesg 관련 로그 : 시스템 부팅 관련 메세지 로그 정보
2) secure 관련 로그 : 사용자 인증으로 SSH 접속 시 인증 등과 같은 로그를 확인
3) messages 관련 로그 : 로그인 정보나 설정 정보 등의 전반적인 메시지의 로그 정보

### 3.1.3 Dataplane 로그 소스
```
// dataplane 로그 소스(/var/log/journal for kubelet.service, kubeproxy.service, and docker.service), 쿠버네티스 데이터플레인 로그
for node in $N1 $N2 $N3; do echo ">>>>> $node <<<<<"; \
ssh ec2-user@$node sudo tree /var/log/journal -L 1; echo; done
```
1) /var/log/journal에는 다양한 로그 정보가 존재
   - kubelet
   - kubeproxy
   - 컨테이너 런타인과 같은 관련 서비스에서 Data Plane 로그를 확인

![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/9bd0d578-11ef-45c7-a136-17d9cc939c08)
1) /var/log/journal에 트리 정보를 확인
   - /var/log/journal 경로에 로그 정보가 난수 형태로 표현.
  
2) kubelet.service와 kubeproxy.service 등의 정보를 확인 가능.

```
// journal 로그 확인 (kubelet 정보)
ssh ec2-user@$N3 sudo journalctl -u kubelet -x -n 200
```
1) dataplane는 노드에 접근해서 journalctl의 명령으로 유닛을 kubelet으로 지정해 확인 가능.
2) /var/log/journal 경로를 통해 kubelet의 로그 200줄 확인 명령어.
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/cc884982-81de-4373-a8e0-c8a2a7635d4e)

1) 어플리케이션 로그와 호스트 로그와 데이터 플레인 로그를 노드의 특정 소스 경로에 저장하고 있다고 이해 필요.

```
ssh ec2-user@$N3 sudo journalctl -u kubelet -f
```

## 3.2. FluentBit 설치 및 확인


### 3.2.1 네임 스페이스 생성
- AWS 공식문서에 FluentBit 설치 가이드가 있음.
  
```
//  Fluentbit가 위치할 네임스페이스 생성
kubectl apply -f https://raw.githubusercontent.com/aws-samples/amazon-cloudwatch-container-insights/latest/k8s-deployment-manifest-templates/deployment-mode/daemonset/container-insights-monitoring/cloudwatch-namespace.yaml
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/b5a294f5-ba82-4470-aac3-bbaf0a1c8591)

```
// 네임스페이스 확인
kubectl get ns
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/157296a3-0766-4fd3-8cc5-616be471f992)

### 3.2.2 FluentBit ConfigMap 생성 (#@ Fluentbit를 생성할 때 설정할 옵션을 정의하는 ConfigMap을 생성)
```
// Fluent-bit ConfigMap 생성
FluentBitHttpServer='On'
FluentBitHttpPort='2020'
FluentBitReadFromHead='Off'
FluentBitReadFromTail='On'

kubectl create configmap fluent-bit-cluster-info \
--from-literal=cluster.name=${CLUSTER_NAME} \
--from-literal=http.server=${FluentBitHttpServer} \
--from-literal=http.port=${FluentBitHttpPort} \
--from-literal=read.head=${FluentBitReadFromHead} \
--from-literal=read.tail=${FluentBitReadFromTail} \
--from-literal=logs.region=${AWS_DEFAULT_REGION} -n amazon-cloudwatch
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/d4fc4693-9659-49d5-9af4-2b897a3d4264)

1) 환경에 따라 설정 인자를 조정

### 3.2.3 FluentBit 생성
```
// Fluentbit 생성
kubectl apply -f https://raw.githubusercontent.com/aws-samples/amazon-cloudwatch-container-insights/latest/k8s-deployment-manifest-templates/deployment-mode/daemonset/container-insights-monitoring/fluent-bit/fluent-bit.yaml
```
1) kubectl apply 명령으로 AWS 공식 문서에서 제공하는 링크로 Fluent Bit를 설치
2) 앞서 구성한 ConfigMap을 활용해 Fluent Bit가 생성
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/4748b908-417e-493f-aae8-091e21e1c4d6)

![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/fdd94ab7-f83e-49c1-b1ae-8a177d0742d1)
1) Kube-Ops-view에서 3개의 모든 노드에 Fluent Bit가 생성 확
   
```
// 설치 확인
kubectl get ds,pod,cm,sa -n amazon-cloudwatch
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/30fb84fc-15c9-476a-821d-b4c90a7ef2e1)
1) Fluentbit Pod를 배포하기 위한 데몬셋이 확인 -> node 1,2,3에 각각 한개씩 총 3대 확인
2) 데몬셋에 의한 생성된 Pod 정보 확인
3) ConfigMap 정보 확인
4) 서비스 아카운트 정보 확인

### 3.2.4 FluentBit ConfigMap 확인
```
// FluentBit Configmap 확인
kubectl get cm fluent-bit-cluster-info -n amazon-cloudwatch -o yaml | yh
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/3006f410-892a-44c5-9440-34b553a7614a)
1) 유형 : configmap
2) 이름 : fluentbit-cluster-info
3) configmap은 amazon-cloudwatch 네임스페이스에 저장
   
```
// FluentBit Configmap 상세 - 로그 INPUT/FILTER/OUTPUT 설정 확인
/// 설정 구성 : application-log.conf, dataplane-log.conf, fluent-bit.conf, host-log.conf, parsers.conf
kubectl describe cm fluent-bit-config -n amazon-cloudwatch
```

1) 해당 명령어를 통해 Fluentbit의 구조를 이해 가능.
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/ae53957b-0654-4cdd-ad97-fae5e92b231d)
1) application-log의 설정 정보 확인 가능

![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/783d3c84-8418-49be-91c3-fb47068723cb)
1) dataplane-log의 설정 정보 확인 가능

![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/ca13cbc9-78e2-471a-8253-9371f429da38)
1) host-log의 설정 정보 확인 가능
2) [INPUT] 영역 :
   - 호스트로그를 위한 소스 경로를 지정 : /var/log/dmesg와 /var/log/messages와 /var/log/secure로 경로가 지정
  
3) [FILTER] 영역으로 필터링 규칙을 정의
4) [OUTPUT] 영역으로 수집된 로그를 전달할 대상을 정의.
   - 대상은 클라우드워치로 /aws/containerinsights/myeks/host 형태로 로그 그룹을 지정
  
5) 결론 : FluentBit는 로그 수집 대상에 대해 INPUT, FILTER, OUTPUT 형태로 정의

### 3.2.5 FluentBit DaemonSet 확인
```
// FluentBit Daemonset 
/// 파드가 수집하는 방법 : Volumes에 HostPath 확인
kubectl describe ds fluent-bit -n amazon-cloudwatch
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/c7fb6f8e-1e95-48bd-8bc2-9141a4a70d3b)
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/6ff7f056-01a3-4ffd-8fdb-0fc1172d536b)
1) 여러가지 정보 출력 중에서 볼륨 영역
   - /var/log, /var/log/dmesg 그리고 다양한 경로에 대해 호스트 패스를 지정
  
2) FluentBit는 HostPath에 해당 경로를 참조해서 로그 정보를 수집

```
// /var/log에 tree 확인
ssh ec2-user@$N1 sudo tree /var/log
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/b23ffc65-46a9-45c8-97c5-2f7b8c7b147a)
1) /var/log 하위 경로에 다양한 디렉토리와 로그 파일이 존재
2) FluentBit는 HostPath로 /var/log를 지정해서 해당 로그를 수집
3) 결론 : FluentBit의 구조와 수집 방식이 이해.

## 3.3. CloudWatch 로그 확인
- FluentBit를 통해 로그를 수집하고 CloudWatch로 전달하는 환경을 구성 완료.
- CloudWatch 로그 확인 시작.

### 3.3.1 신규 터미널 모니터링
```
kubectl logs deploy/nginx -f
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/9b4bfc86-79cf-4d13-bde4-ae50f3fe1d42)
1) nginx 컨테이너의 어플리케이션 로그를 확인하는 모니터링을 수행

### 3.3.2 부하 발생
```
yum install -y httpd

ab -c 500 -n 30000 https://nginx.$MyDomain/
```
1) 다량의 HTTPS 접근을 위한 아파치 벤치마킹 툴을 설치하고 약 3만회 접근을 수행 -> 모니터링
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/26bcbcae-92cf-4b71-80e9-76aaa694eebe)
1) Nginx 로그 정보에 다량의 접속 로그가 출력확인
2) 로그를 통해 이상현상을 확인하고 그에 따른 조치를 취할 수 있음.
```
관리 콘솔에 CloudWatch 로그 그룹에서 application 로그 그룹을 선택 –> 로그 스트림 필터링 nginx –> ApacheBench 필터링 후 확인합니다.
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/6f699183-38cc-4517-b169-0755f8f7e5e4)
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/45a127da-e454-47a2-b3c6-f9bd29f28441)
1) 어플리케이션 로그 그룹을 선택
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/5830a33d-e6b3-4022-8b89-35154405d2f8)
1) 대상 Nginx 로그 스트림을 선택
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/c72868c5-d9e8-40ac-a616-9df0bb471d43)
1) 로그 이벤트 정보 -> 여기서 이벤트 필터링에 ApacheBench를 입력
2) 아파치 벤치마킹 도구로 3만회 접속을 시도한 로그들만 출력 확인.

### 3.3.3 Log Insight 정보 확인
```
// Log Insight 컨테이너 이름별 애플리케이션 로그 오류 카운트
// 로그 그룹 선택 : /aws/containerinsights/<CLUSTER_NAME>/application
stats count() as error_count by kubernetes.container_name 
| filter stream="stderr" 
| sort error_count desc
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/84e6cefd-9dbb-4b98-abb1-fcb5791925a5)
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/6de080cb-cdcb-4e0b-b625-2f48650dee77)

```
// 컨테이너 프로세스 강제 종료
kubectl exec deploy/nginx -c nginx -- kill -s SIGINT 1
```
1) 컨테이너 프로세스를 강제로 종료시켜 노드에서 확인되는 에러 카운트를 확인

![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/182c264c-e303-40e8-bb01-c9df57804443)
1) nginx 컨테이너가 다시 실행되지 않은 상태에서 명령을 수행하니 다음과 같은 에러가 발생
   
```
// 노드에서 컨테이너 에러 카운트
// 로그 그룹 선택 : /aws/containerinsights/<CLUSTER_NAME>/host
fields @timestamp, @message, ec2_instance_id
| filter  message like 'level=error' or message like 'level=warning' 
| stats count(*) as error_count by ec2_instance_id
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/86ac8fce-ef95-49ee-b84c-6280813f664e)
1) 에러 발생 카운트가 발생한 것을 확인

## 3.4. 실습 자원 삭제


### 3.4.1 실습 종료 후 자원 삭제
```
// fluent-bit 삭제
kubectl delete ds fluent-bit -n amazon-cloudwatch && kubectl delete cm fluent-bit-cluster-info -n amazon-cloudwatch && kubectl delete cm fluent-bit-config -n amazon-cloudwatch && kubectl delete sa fluent-bit -n amazon-cloudwatch

// bitnami nginx 삭제
helm uninstall nginx

// 로그 그룹 삭제 : 데이터 플레인
aws logs delete-log-group --log-group-name /aws/containerinsights/$CLUSTER_NAME/application
aws logs delete-log-group --log-group-name /aws/containerinsights/$CLUSTER_NAME/dataplane
aws logs delete-log-group --log-group-name /aws/containerinsights/$CLUSTER_NAME/host
aws logs delete-log-group --log-group-name /aws/containerinsights/$CLUSTER_NAME/performance
```

```
Warning: 다음 섹션의 실습을 이어서 진행할 것으로 Amazon EKS 원클릭 배포를 유지합니다. 혹시나 다음 섹션을 진행하지 않을 경우 4장 Amazon EKS 원클릭 배포를 삭제해 주길 바랍니다.
```


   

























