# 2. [실습] Amazon EKS 원클릭 배포 및 확인
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/f2f9b526-ea2e-4dc5-9f3a-dc278cb012ac)

# 1. Amazon EKS 원클릭 배포
- 4장의 실습을 위한 기본 인프라 환경과 Amazon EKS 클러스터 배포에 대해 CloudFormation을 통해 원클릭 배포를 수행하는 가이드.
- Amazon EKS 원클릭 배포를 통해 실습 구성.

## 1.1. CloudFormation 스택 생성
- 파라미터를 입력 후 스택을 생성
- Note: AWS 관리 콘솔에 로그인 할때 IAM 사용자 계정으로 진행

### 1.1.1 [관리 콘솔] CloudFormation 파라미터 설정
- 스택 생성 페이지에서 다음 버튼을 클릭
- 스택 이름은 [myeks]로 입력
- KeyName은 [각자의 키페어]를 선택
- MyIAMUserAccessKeyID는 [각자의 액세스 키 ID 값]을 입력
- MyIAMUserSecretAccessKey는 [각자의 시크릿 액세스 키 값]을 입력
- SgIngressSshCidr는 [각자의 PC의 퍼블릭 IP 주소/32]로 입력
- 나머지 파라미터는 기본 값을 유지하고 다음 버튼을 클릭
- Warning: 설정을 마치고 약 20분 정도 대기 시간이 흐른 뒤 기본 인프라 환경과 Amazon EKS 클러스터 생성이 완료. 반드시 해당 대기 시간이 지난 후 다음 작업을 수행

## 1.2. CloudFormation 스택 생성 확인
- Amazon EKS 원클릭 배포를 수행하면 AWS CloudFormation 스택 9개가 생성

### 1.2.1 CloudFormation 스택 정보
- myeks: 기본 인프라 생성을 정의한 스택
- eksctl-myeks-cluster: eks 클러스터 생성을 정의한 스택
- eksctl-myeks-addon-vpc-cni: vpc cni를 위한 IAM 역할을 정의한 스택
- eksctl-myeks-nodegroup-ng1: eks 클러스터의 관리형 노드 그룹을 정의한 스택
- eksctl-myeks-addon-iamserviceaccount-kube-system-aws-load-balancer-controller: aws load balancer controller를 위한 IRSA를 정의한 스택
- eksctl-myeks-addon-ebs-csi-driver: ebs-csi-driver를 정의한 스택
- eksctl-myeks-addon-efs-csi-driver: efs-csi-driver를 정의한 스택
- eksctl-myeks-addon-iamserviceaccount-kube-system-ebs-csi-controller-sa: ebs-csi-controller를 위한 IRSA를 정의한 스택
- eksctl-myeks-addon-iamserviceaccount-kube-system-efs-csi-controller-sa: efs-csi-controller를 위한 IRSA를 정의한 스택
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/73730950-2e2a-4aba-9d79-c967198674b3)
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/f56a2cd6-5919-4475-ae71-85433b7536e2)

- Note: myeks 스택의 출력 탭에서 관리용 인스턴스의 퍼블릭 IP 주소를 확인.
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/120345ef-dd9b-4711-9a5b-bcadf62c2ae6)


# 2. Amazon EKS 원클릭 배포 정보 확인
- AWS CloudFormation 스택의 출력 탭에서 eksctlhost의 퍼블릭 IP를 확인
- 해당 IP로 EKS 관리용 인스턴스(myeks-bastion-EC2)에 SSH로 접속하고 아래 명령어를 통해 정보를 확인

## 2.1. 기본 정보 확인
- Amazon EKS 원클릭으로 배포된 기본 정보와 설정을 진행

### 2.1.1 Default Namespace로 적용
```
// Default Namespace로 위치 변경
kubectl ns default
```

### 2.1.2 노드의 프라이빗 IP 변수 선언
```
//  3대의 워커노드의 Private IP 주소 변수 저장
N1=$(kubectl get node --label-columns=topology.kubernetes.io/zone --selector=topology.kubernetes.io/zone=ap-northeast-2a -o jsonpath={.items[0].status.addresses[0].address})

N2=$(kubectl get node --label-columns=topology.kubernetes.io/zone --selector=topology.kubernetes.io/zone=ap-northeast-2b -o jsonpath={.items[0].status.addresses[0].address})

N3=$(kubectl get node --label-columns=topology.kubernetes.io/zone --selector=topology.kubernetes.io/zone=ap-northeast-2c -o jsonpath={.items[0].status.addresses[0].address})

// 3대의 워커노드의 Private IP 주소 전역 변수로 선언 및 확인
echo "export N1=$N1" >> /etc/profile

echo "export N2=$N2" >> /etc/profile

echo "export N3=$N3" >> /etc/profile

echo $N1, $N2, $N3
```

### 2.1.2 작업용 인스턴스에서 노드로 보안 그룹 설정
```
// 노드 보안 그룹 ID를 변수 선언
NGSGID=$(aws ec2 describe-security-groups --filters Name=group-name,Values=*ng1* --query "SecurityGroups[*].[GroupId]" --output text)

// 노드 보안 그룹에 정책 추가 - 작업용 인스턴스에서 노드로 모든 통신 허용
aws ec2 authorize-security-group-ingress --group-id $NGSGID --protocol '-1' --cidr 192.168.1.100/32
```

### 2.1.3 EFS 마운트 확인
```
// NFS4로 마운트 된 디스크 확인
df -hT --type nfs4

// 만약 마운트가 되지 않는다면..
mount -t nfs4 -o nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,noresvport $EFS_ID.efs.ap-northeast-2.amazonaws.com:/ /mnt/myefs
```

### 2.1.4 워커 노드 SSH 접근 확인
```
// N1, N2, N3 워커 노드에 SSH 접속 후 hostname 명령어 수행
for node in $N1 $N2 $N3; do ssh ec2-user@$node hostname; done
```

## 2.2. 기본 설정 작업
- 4장에서 실습할 다양한 도구 설치와 기본 설정을 수행

### 2.2.1 AWS Load Balancer Controller 설치
```
helm repo add eks https://aws.github.io/eks-charts

helm repo update

helm install aws-load-balancer-controller eks/aws-load-balancer-controller -n kube-system --set clusterName=$CLUSTER_NAME \
  --set serviceAccount.create=false \
  --set serviceAccount.name=aws-load-balancer-controller
```

### 2.2.2 ExternalDNS 설치
```
MyDomain=<자신의 도메인>

MyDnsHostedZoneId=$(aws route53 list-hosted-zones-by-name --dns-name "${MyDomain}." --query "HostedZones[0].Id" --output text)

echo $MyDomain, $MyDnsHostedZoneId

curl -s -O https://raw.githubusercontent.com/cloudneta/cnaeblab/master/_data/externaldns.yaml

MyDomain=$MyDomain MyDnsHostedZoneId=$MyDnsHostedZoneId envsubst < externaldns.yaml | kubectl apply -f -
```

### 2.2.3 kube-ops-view 설치
```
helm repo add geek-cookbook https://geek-cookbook.github.io/charts/

helm install kube-ops-view geek-cookbook/kube-ops-view --version 1.2.2 --set env.TZ="Asia/Seoul" --namespace kube-system

kubectl patch svc -n kube-system kube-ops-view -p '{"spec":{"type":"LoadBalancer"}}'

kubectl annotate service kube-ops-view -n kube-system "external-dns.alpha.kubernetes.io/hostname=kubeopsview.$MyDomain"

echo -e "Kube Ops View URL = http://kubeopsview.$MyDomain:8080/#scale=1.5"
```

### 2.2.4 스토리지 클래스 생성
1) 프로메테우스 서버에 TSDB가 사용할 스토리지 대상을 지정 필요.
   - 별도의 설정이 없으면 로컬 내에 Empty DIR 볼륨을 사용.
   - 실습은 영구 볼륨에 PV와 연결해서 진행.
  
2) 그라파나 또한 데이터를 저장하는 목적에 스토리지 영역을 지정할 수 있음.
   - 실습은 영구 볼륨에 PV와 연결해서 진행.
  
3) ebs-csi.driver를 통한 동적 프로비저닝 구성하여 진행.
   - pv를 정의하는 storageClass가 필요.
   
```
// 스토리지 클래스 생성을 위한 gp3-sc.yaml 파일 만들기
cat <<EOT > gp3-sc.yaml
kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: gp3
allowVolumeExpansion: true  // #@ EBS CSI 컨트롤러의 리사이저에 의해 라이브 상태에서 볼륨 사이즈를 증가하는 기능
provisioner: ebs.csi.aws.com
volumeBindingMode: WaitForFirstConsumer  // #@ PVC에 최초 파드가 연결될 때 PV를 생성하고 바인딩 수행.
parameters:
  type: gp3
  allowAutoIOPSPerGBIncrease: 'true'
  encrypted: 'true'
EOT

// gp3 스토리지 클래스 생성
kubectl apply -f gp3-sc.yaml

// 스토리지 클래스 확인
kubectl get sc
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/1a2e65d3-57e1-495e-b140-c0584f64f0ca)

### 2.2.5 AWS Cert Manager 인증서 확인
1) 특정 대상의 접근을 인그레스 유형의 ALB로 수행예정.
2) 자신의 도메인에 서브 도메인을 구성하고 연결해서 해당 주소를 사용
3) HTTPS를 통한 접근 설정 필요.
   - 자신의 도메인으로 HTTPS 접근을 위한 ACM 인증서를 발급받아야 함.
   - region 별로 독립된 형태로 AWS Certificate Manager에서 인증서 관리를 수행
     
```
// ACM 인증서 확인
aws acm list-certificates

// ACM 인증서 변수 선언
CERT_ARN=`aws acm list-certificates --query 'CertificateSummaryList[].CertificateArn[]' --output text`; echo $CERT_ARN
```

만약 인증서가 없을 경우..
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/f722f1a9-9e07-4f47-ac47-c25b76534d3c)

### ACM 인증서 생성
```
// ACM 인증서 신규 생성
aws acm request-certificate \
  --domain-name *.${MyDomain} \
  --validation-method DNS \
  --options CertificateTransparencyLoggingPreference=DISABLED
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/a74fdd86-d766-4c25-87d9-a21d1ad0c747)
1) 위 AWS CLI 명령으로 ACM 인증서를 생성
2) ACM 인증서를 요청
   - 도메인 이름은 ***.자신의 도메인 주소** 형태
   - 도메인 주소 앞에 모든 서브 도메인으로 구성된 주소를 지칭
  
3) 인증 확인 방법
   - DNS를 통해 작업 진행
   - 인증 확인용 DNS 레코드를 생성하면 처리됨.
   - 명령어 입력 후 인증서 ARN이 출력 확인.

![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/d0c9cfdf-cb11-4d8b-8e99-e537f0f3931d)

4) 현재 인증서가 검증된 상태가 아닌 검증 대기 중 상태 (Status: PENDING_VALIDATION)
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/50772731-52f2-4c86-b627-ce5911a645ed)

5) AWS 콘솔의 ACM 서비스에서 인증서 나열 메뉴로 진입하면 앞서 생성한 인증서 확인 가능. (현재 상태는 검증 대기 중 상태)

![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/3955b7d7-10a5-4bbc-a5d9-cf576d955b00)

6) 해당 인증서 아이디를 클릭해서 진입 (인증서 상세 정보 진입)
   - 검증방법을 **DNS 방식을 사용하여** 검증 진행. -> **Route 53의 레코드를 생성하여 검증하는 방식**
  
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/759fcf6a-0645-4d71-83c3-d6dfc2473c11)

7) Route 53에서 레코드 생성을 선택하면
   - 검증에 사용할 DNS 레코드가 자동 출력됨.
   - 레코드 생성 버튼을 누르면 검증이 진행.

![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/dc837c33-0cfe-4556-a5c1-7f309d7fb4d6)
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/f1f31ef8-8710-46b6-ae20-b20dd62d0019)

8) 1분 내외의 시간을 대기하면 발급됨
   - ACM 인증서 리스트를 확인해보면 정상적으로 인증서가 발급 상태로 전환 확인.
   - *.ongja.click에 대한 인증서가 생성 완료.

### 관리 콘솔에서 AWS Certificate Manager 서비스로 진입하여 다음과 같은 단계로 작업 수행
1. 인증 대기 중인 인증서 ID를 선택
2. 도메인 영역에서 Route 53에서 레코드 생성 버튼 클릭
3. 레코드 생성 버튼을 클릭
4. 약간의 대기 후 발급 상태로 전환 확인

### ACM 인증서 확인 및 변수 선언
```
// ACM 인증서 확인
aws acm list-certificates
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/de4986ad-4a1f-4044-bab4-5d686620444e)

```
// ACM 인증서 변수 선언
CERT_ARN=`aws acm list-certificates --query 'CertificateSummaryList[].CertificateArn[]' --output text`; echo $CERT_A
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/29bc0fb1-c619-43f6-8b13-0a353794fa03)
1) 인증서의 ARN을 변수로 저장 완료.
   - 해당 인증서는 삭제할 필요 없이 앞으로 자신의 도메인의 인증서가 필요할 때 사용하면 됨.

### 2.2.6 설치 정보 확인
```
// 이미지 정보 확인
kubectl get pods --all-namespaces -o jsonpath="{.items[*].spec.containers[*].image}" | tr -s '[[:space:]]' '\n' | sort | uniq -c
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/7c890128-32f8-4369-8499-261120086840)
1) EKS 원클립 배포로 설치한 add-on이나 직접 설치한 도구들의 이미지 파일들 확인.
   
```
// Add-On 정보 확인
eksctl get addon --cluster $CLUSTER_NAME
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/951dc070-0694-4037-a37c-e64c8e9e9f04)
1) vpc-cni와 kube-proxy와 core-dns뿐 아니라 aws-ebs-csi 드라이버와 AWS EFS CSI 드라이버도 설치되고 활성화 상태 확인.
   
```
// IRSA 확인
eksctl get iamserviceaccount --cluster $CLUSTER_NAME
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/e337bd7e-73d3-4dfb-a8f2-8fb7d245c459)
1) AWS 로드밸런스 컨트롤러와 EBS CSI 컨트롤러와 EFS CSI 컨트롤러의 IRSA가 생성된 것을 확인

# 3. 실습 환경 삭제
- Amazon EKS 원클릭을 통해 배포된 모든 자원을 삭제

## 3.1 Amazon EKS 원클릭 배포의 삭제
```
// kube-ops-view 삭제
helm uninstall -n kube-system kube-ops-view

// Amazon EKS 원클릭 배포의 삭제
eksctl delete cluster --name $CLUSTER_NAME \
  && aws cloudformation delete-stack --stack-name $CLUSTER_NAME
```
- Warning: Amazon EKS 원클릭 배포의 삭제는 약 15분 정도 소요. 삭제가 완료될 때 까지 SSH 연결 세션을 유지
- Warning: 만약에 CloudFormation 스택이 삭제되지 않는다면 수동으로 VPC(myeks-VPC )를 삭제 후 CloudFormation 스택을 다시 삭제





   

























