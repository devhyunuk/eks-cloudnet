# 1. [실습] Amazon EKS 원클릭 배포 및 확인
1) Amazon EKS 원클릭 배포 및 확인
2) 임시 파일 시스템과 emptyDir 구성
3) local-path-provisioner 구성

[자동 구성도]
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/a888e506-16ca-4a88-9fb2-4e98c08eb7e4)

1) **2장 Amazon EKS 원클릭 배포**
   - VPC 환경이 구성 -> EKS 클러스터에 워커노드 구성 -> 모든 자원을 관리하는 용도로 작업용 EC2 Bastion Host 인스턴스도 구성
   - 아마존 EKS 클러스터 생성 -> 관리형 노드그룹이 구성 -> AWS 관리형으로 컨트롤 플레인이 구성 -> 노드그룹을 통해 워커노드 3대를 구성
   - 다양한 add-on과 실습 도구가 구성 -> 필요한 변수를 미리 선언 구성
2) **3장 Amazon EKS 원클릭 배포 추가 사항**
   - 아마존 EFS 파일 시스템을 생성 -> 작업용 인스턴스에 마운트하는 작업 수행
   - 3개의 가용 영역에서 구성된 VPC 환경에서 -> Amazon EFS 파일 시스템을 생성하고 -> 마운트 타겟을 각각의 가용 영역에 연결
   - 사전에 EFS 용도로 보안 그룹도 생성하고 연결 필요
   - 작업용 EC2 Bastion Host 인스턴스에서 -> EFS 파일 시스템에 마운트하여 연결하는 작업까지 수행 (작업용 인스턴스는 마운트 경로로 생성된 파일 시스템을 사용할 수 있음)
   - AWS LoadBalancer Controller의 권한이임을 위해 irsa도 미리 정의해서 생성
    
[원클릭 배포 아키텍처]
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/692f2da2-9066-48ed-9c61-63f2a325b5c5)

1) myeks vpc가 생성 -> 3개의 가용 영역에서 public subnet 3개와 private subnet 3개 생성
2) 작업용 EC2 Bastion Host 인스턴스가 public subnet 1에 생성
3) Amazon EKS 클러스터 생성 수행 :
   - AWS Managed VPC의 컨트롤 플레인 생성
   - 관리형 노드그룹을 설정해서 -> 3개의 가용 영역에서 Public Subnet에 WorkerNode가 하나씩 구성
 
4) Amazon EFS 파일 시스템을 구성하고 -> 작업용 EC2 Bastion Host 인스턴스 마운트
5) AWS LoadBalancer Controller가 사용할 IRSA 생성

---

# 1. Amazon EKS 원클릭 배포
- 3장의 실습을 위한 기본 인프라 환경과 Amazon EKS 클러스터 배포에 대해 CloudFormation을 통해 원클릭 배포를 수행 가이드
- Amazon EKS 원클릭 배포 (실습 구성의 시간 절약, 목표 학습 내용 집중)

## 1.1. CloudFormation 스택 생성
- AWS CloudFormation 페이지로 이동 -> 파라미터를 입력 후 스택을 생성
- Note: AWS 관리 콘솔에 로그인 할때 IAM 사용자 계정으로 진행

[관리 콘솔] CloudFormation 파라미터 설정
- 스택 생성 페이지에서 다음 버튼을 클릭
- 스택 이름은 [myeks]로 입력
- KeyName은 [각자의 키페어]를 선택
- MyIAMUserAccessKeyID는 [각자의 액세스 키 ID 값]을 입력
- MyIAMUserSecretAccessKey는 [각자의 시크릿 액세스 키 값]을 입력
- SgIngressSshCidr는 [각자의 PC의 퍼블릭 IP 주소/32]로 입력
- 나머지 파라미터는 기본 값을 유지하고 다음 버튼을 클릭
- Warning: 설정을 마치고 약 20분 정도 대기 시간이 흐른 뒤 기본 인프라 환경과 Amazon EKS 클러스터 생성이 완료.

## 1.2. CloudFormation 스택 생성 확인
- Amazon EKS 원클릭 배포를 수행하면 AWS CloudFormation 스택 5개가 생성

[CloudFormation 스택 정보]
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/b827c9b4-e044-417f-b79e-37488034fe5f)
- myeks: 기본 인프라 생성을 정의한 스택
- eksctl-myeks-cluster: eks 클러스터 생성을 정의한 스택
- eksctl-myeks-addon-vpc-cni: vpc cni를 위한 IAM 역할을 정의한 스택
- eksctl-myeks-nodegroup-ng1: eks 클러스터의 관리형 노드 그룹을 정의한 스택
- eksctl-myeks-addon-iamserviceaccount-kube-system-aws-load-balancer-controller: aws load balancer controller를 위한 IRSA를 정의한 스택
- Note: myeks 스택의 출력 탭에서 관리용 인스턴스의 퍼블릭 IP 주소를 확인
---
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/368de163-c97d-479a-88f9-f2cf42fd7c64)
---


# 2. Amazon EKS 원클릭 배포 정보 확인
- AWS CloudFormation 스택의 출력 탭에서 eksctlhost의 퍼블릭 IP를 확인
- 해당 IP로 EKS 관리용 인스턴스(myeks-bastion-EC2)에 SSH로 접속하고 아래 명령어를 통해 정보를 확인

## 2.1. 기본 정보 확인
- Amazon EKS 원클릭으로 배포된 기본 정보와 설정을 진행합니다.

### 2.1.1 Default Namespace로 적용
```
// Default Namespace로 위치 변경
kubectl ns default
```

### 2.1.2 노드의 프라이빗 IP 변수 선언
```
//  3대의 워커노드의 Private IP 주소 변수 저장
N1=$(kubectl get node --label-columns=topology.kubernetes.io/zone --selector=topology.kubernetes.io/zone=ap-northeast-2a -o jsonpath={.items[0].status.addresses[0].address})

N2=$(kubectl get node --label-columns=topology.kubernetes.io/zone --selector=topology.kubernetes.io/zone=ap-northeast-2b -o jsonpath={.items[0].status.addresses[0].address})

N3=$(kubectl get node --label-columns=topology.kubernetes.io/zone --selector=topology.kubernetes.io/zone=ap-northeast-2c -o jsonpath={.items[0].status.addresses[0].address})

// 3대의 워커노드의 Private IP 주소 전역 변수로 선언 및 확인
echo "export N1=$N1" >> /etc/profile

echo "export N2=$N2" >> /etc/profile

echo "export N3=$N3" >> /etc/profile

echo $N1, $N2, $N3
```

### 2.1.3 작업용 인스턴스에서 노드로 보안 그룹 설정
```
// 노드 보안 그룹 ID를 변수 선언
NGSGID=$(aws ec2 describe-security-groups --filters Name=group-name,Values=*ng1* --query "SecurityGroups[*].[GroupId]" --output text)

// 노드 보안 그룹에 정책 추가 - 작업용 인스턴스에서 노드로 모든 통신 허용
aws ec2 authorize-security-group-ingress --group-id $NGSGID --protocol '-1' --cidr 192.168.1.100/32
```

### 2.1.4 노드에 Tool 설치
```
// 노드 1, 2, 3에 유용한 Tool 설치
ssh ec2-user@$N1 sudo yum install links tree jq tcpdump sysstat -y

ssh ec2-user@$N2 sudo yum install links tree jq tcpdump sysstat -y

ssh ec2-user@$N3 sudo yum install links tree jq tcpdump sysstat -y
```

### 2.1.5 EFS 마운트 확인
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/008112d8-d6f3-4b55-b96d-2e5b8aa471dc)
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/44cbd488-5e79-4b1b-93c8-9b09977893fc)
1) EKS 원클립 배포로 아마존 EFS 생성과 작업용 인스턴스에서 마운트를 수행했음
---
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/477d5b6b-91fb-4c92-885d-41dfe0e3540b)
1) 3개의 가용 영역에 구성된 마운트 타겟 확인
2) 보안 그룹도 적용 확인
---
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/6150efe0-23ca-409e-8fb0-73ab97b9fd42)
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/20f4a4b6-3f73-420a-a65d-88f7c77cb81c)
1) EFS -> 연결 버튼 -> 대상에서 마운트하는 방법 -> 해당 명령어 형태로 EKS 원클리 배포때 이미 수행
---

```
// NFS4로 마운트 된 디스크 확인
df -hT --type nfs4
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/bb07ce3d-bf41-4b95-bdcd-d3b3ac5efad3)
1) df 명령어로 마운트 대상을 확인 -> 유형을 NFS4로 지정해서 확인
2) EFS NFS4 유형으로 마운트된 것을 확인
3) 사이즈는 8 엑사바이트 (EFS는 무한에 가까운 용량 제공)
4) 마운트 경로는 /mnt/myefs로 지정 확인.

```
mount | grep nfs4
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/bf87d1d1-7457-46e7-bce7-2ead947da6c1)

```
// EFS에 파일 생성, 확인, 삭제
echo "efs file test" > /mnt/myefs/memo.txt

cat /mnt/myefs/memo.txt

rm -f /mnt/myefs/memo.txt
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/4fd316e9-2e59-493e-9c83-4dc15b7628eb)
1) 해당 경로에 마운트된 EFS 파일 시스템에 memo.txt 파일이 저장.


### 2.1.5.1 만약 마운트가 되지 않는다면..

### 2.1.5.2 EFS 마운트
```
// EFS 파일 시스템 ID 변수 지정
EFS_ID=$(aws efs describe-file-systems --query "FileSystems[?Name=='myeks-EFS'].[FileSystemId]" --output text); echo $EFS_ID

// 작업용 인스턴스에 EFS 마운트
mount -t nfs4 -o nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,noresvport $EFS_ID.efs.ap-northeast-2.amazonaws.com:/ /mnt/myefs
```

### 2.1.5.3 Default StorageClass 확인
```
// Default StorageClass 확인 (gp2)
kubectl get sc
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/2a27fbd7-aab0-46d6-a505-fb86454c2836)
1) 기본적으로 구성되는 디폴트 스토리지 클래스에 대해서 확인
2) get sc 명령으로 현재 생성된 스토리지 클래스를 확인
3) GP2라는 스토리지 클래스 기본값으로 존재
4) StorageClass는 Provisioner 대상을 지정하고 다양한 옵션을 지정할 수 있음

```
kubectl get sc gp2 -o yaml | yh
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/58fdf2b0-22f5-41e4-9833-f450e40fc91b)

1) 유형 : 스토리지 클래스
2) 이름 : GP2
3) 파라미터 :
   - 볼륨 유형 : GP2
   - 파일 시스템 유형 : EXD4
  
4) 프로비저너 대상 : Kubernetes에 내장된 AWS EBS로 설정
5) 디폴트 스토리지 클래스를 사용하지 않고 새로 생성
6) 이유 : GP2 자체의 성능도 떨어져 GP3가 더 좋은 대안이며 Provisioner는 CSI 드라이버에서 생성되는 대상을 사용.

## 2.2. AWS LB Controller, ExternalDNS, kube-ops-view 설치
- 2장에서 실습한 AWS Load Balancer Controller, ExternalDNS, kube-ops-view를 설치

## 2.2.1 AWS Load Balancer Controller 설치
```
helm repo add eks https://aws.github.io/eks-charts

helm repo update

helm install aws-load-balancer-controller eks/aws-load-balancer-controller -n kube-system --set clusterName=$CLUSTER_NAME \
  --set serviceAccount.create=false \
  --set serviceAccount.name=aws-load-balancer-controller
```

## 2.2.2 ExternalDNS 설치
```
MyDomain=<자신의 도메인>

MyDnsHostedZoneId=$(aws route53 list-hosted-zones-by-name --dns-name "${MyDomain}." --query "HostedZones[0].Id" --output text)

echo $MyDomain, $MyDnsHostedZoneId

curl -s -O https://raw.githubusercontent.com/cloudneta/cnaeblab/master/_data/externaldns.yaml

MyDomain=$MyDomain MyDnsHostedZoneId=$MyDnsHostedZoneId envsubst < externaldns.yaml | kubectl apply -f -
```

## 2.2.3 kube-ops-view 설치
```
helm repo add geek-cookbook https://geek-cookbook.github.io/charts/

helm install kube-ops-view geek-cookbook/kube-ops-view --version 1.2.2 --set env.TZ="Asia/Seoul" --namespace kube-system

kubectl patch svc -n kube-system kube-ops-view -p '{"spec":{"type":"LoadBalancer"}}'

kubectl annotate service kube-ops-view -n kube-system "external-dns.alpha.kubernetes.io/hostname=kubeopsview.$MyDomain"

echo -e "Kube Ops View URL = http://kubeopsview.$MyDomain:8080/#scale=1.5"
```

## 2.2.4 설치 정보 확인
```
// 이미지 정보 확인
kubectl get pods --all-namespaces -o jsonpath="{.items[*].spec.containers[*].image}" | tr -s '[[:space:]]' '\n' | sort | uniq -c
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/abbaf6cd-e603-4c02-ad53-6201445cf021)
1) Pod에 존재하는 컨테이너 이미지를 확인
2) AWS 자체의 add-on 형태로 제공하는 vpc-cni, core-dns, kube-proxy의 컨테이너 이미지를 확인
3) kube-ops-view와 AWS LoadBalancer Controller와 externalDNS도 확인

```
// Add-On 정보 확인
eksctl get addon --cluster $CLUSTER_NAME
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/78e65fb9-633c-4d5e-80bb-b7f95b6d25e9)
1) VPC CNI는 IAM 역할이 정의되어 VPC 자원을 관리할 수 있음을 확인

```
// IRSA 확인
eksctl get iamserviceaccount --cluster $CLUSTER_NAME
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/ef682f43-7249-4760-ab95-a7d73175ad3b)
1) AWS LoadBalancer Controller의 IRSA를 확인 -> 해당 권한으로 AWS ELB를 관리할 수 있음 확인.
























