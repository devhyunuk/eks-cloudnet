# 2. [실습] 기본 네트워크 환경 확인 - 2.md

## 1.3 테스트용 파드 생성 및 확인
- 테스트용으로 netshoot 파드를 3대 생성하고 관련 정보를 확인
   
#### 1.3.1 신규 터미널 3개에 워커 노드 모니터링 수행
```
// 워커 노드1의 모니터링
ssh ec2-user@$N1

watch -d "ip link | egrep 'eth|eni' ;echo;echo "[ROUTE TABLE]"; route -n | grep eni"

// 워커 노드2의 모니터링
ssh ec2-user@$N2

watch -d "ip link | egrep 'eth|eni' ;echo;echo "[ROUTE TABLE]"; route -n | grep eni"

// 워커 노드3의 모니터링
ssh ec2-user@$N3

watch -d "ip link | egrep 'eth|eni' ;echo;echo "[ROUTE TABLE]"; route -n | grep eni"
Note: 신규 터미널을 3개 추가하고 작업용 인스턴스에 진입한 후 워커 노드 1, 2, 3으로 각각 SSH 접근을 합니다.
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/f7975267-2805-4495-9d88-9f3a3f7c3261)
[워커노드 1, 2]
1) 워커노드 1번 같은 경우는 eth0인 Primary ENI와 eth1의 Secondary ENI가 있음 확인
2) 가상의 인터페이스가 coredns Pod(eni1b46...)에 페어링 되어 연결된 것을 확인

![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/c6fae9e0-5b16-48b4-b11b-d862f8aaaead)
[워커노드 3]
1) 워커노드 3번 같은 경우는 eht0인 Primary ENI만 존재하고 별도의 가상의 인터페이스(coredns Pod등이) 없음 확인 : 별도 Pod가 생성되지 않아서

---

#### 1.3.2 테스트용 netshoot 파드 3대 생성
```
- 테스트용 파드는 간단한 디버깅이나 테스트를 수행하는 용도의 netshoot이라는 컨테이너 이미지를 사용.
- 참고 링크: nicolaka/netshoot

cat <<EOF | kubectl create -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: netshoot-pod
spec:
  replicas: 3
  selector:
    matchLabels:
      app: netshoot-pod
  template:
    metadata:
      labels:
        app: netshoot-pod
    spec:
      containers:
      - name: netshoot-pod
        image: nicolaka/netshoot
        command: ["tail"]
        args: ["-f", "/dev/null"]
      terminationGracePeriodSeconds: 0
EOF
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/12083e47-025b-41b5-bf08-d1c5d2918e55)
[워커노드 1]
1) 워커노드 1에 가상의 인터페이스(enid286...)가 추가되고 192.168.1.197의 경로를 생성
2) 해당 IP 주소는 새롭게 생성된 Pod의 IP 주소로 할당된것을 확인

![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/fee96744-855d-47b3-8f2f-f0b0add94f88)
[워커노드 2]
1) 워커노드 2도 마찬가지로 가상의 인터페이스가 추가되고 신규 Pod와 연결이 되었음

![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/0814dfa4-8efe-44e5-a7be-3994cde07265)
[워커노드 3]
1) 워커노드 3도 가상의 인터페이스가 추가되고 신규파드에 연결
2) eht1 인터페이스가 추가
3) eth1 인터페이스는 secondary ENI로 최초 신규파드가 생성됨에 따라 secondary ENI가 생성

---

#### 1.3.3 테스트용 파드 이름 변수 저장
```
// 파드 이름을 변수에 저장
PODNAME1=$(kubectl get pods -o custom-columns=:.metadata.name,PodIP:status.podIP | grep 192.168.1. | cut -c -29)

PODNAME2=$(kubectl get pods -o custom-columns=:.metadata.name,PodIP:status.podIP | grep 192.168.2. | cut -c -29)

PODNAME3=$(kubectl get pods -o custom-columns=:.metadata.name,PodIP:status.podIP | grep 192.168.3. | cut -c -29)
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/c5ed94f1-d6ce-4639-8628-603365344d2b)

---
#### 1.3.4 테스트용 파드 exec 접속 후 네트워크 정보 확인
```
// 테스트용 파드 1에 zsh 접근
kubectl exec -it $PODNAME1 -- zsh
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/16cec332-0f8b-42a3-b59b-076bf098c2d4)


```
// 테스트용 파드에 인터페이스 및 IP 확인
kubectl exec -it $PODNAME1 -- ip -br -c addr

kubectl exec -it $PODNAME2 -- ip -br -c addr

kubectl exec -it $PODNAME3 -- ip -br -c addr
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/2dababfe-285e-41c4-a16b-17f96902b87a)

```
// 테스트용 파드 1에서 다른 파드로 ping 테스트
kubectl exec -it $PODNAME1 -- ping -c 2 [POD-2_IP]

kubectl exec -it $PODNAME1 -- ping -c 2 [POD-3_IP]
```
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/97a5e54b-7a65-4148-9b28-5662a947705a)

![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/ad91ecf8-4df3-49ed-b249-c3a3f674d8d2)
- Pod 1에서 2, 3으로 ping 테스트시 정상동작하는 것을 확인

#### 파드 3대 추가 배포 시 구성 확인
![image](https://github.com/devhyunuk/eks-cloudnet/assets/49749510/e6da721f-6352-43ee-a69d-fa34b9ab6cdc)
1) 각각의 노드에 Pod 한 대씩 총 세대가 구성되는데 되었음 (POD-1, POD-2, POD-3)
2) 해당 Pod는 통신을 위해 노드의 가상 인터페이스와 페어링되어 라우터에 연결
   - POD-1 -> eni337...
   - POD-2 -> eni474...
   - POD-3 -> eni953...
  
3) Pod1과 Pod2를 살펴보면 신규 Pod 생성에 따라 Slot과 ENI를 검토
   - Node1과 Node2는 Secondary ENI가 이미 존재 했음(coreDNS Pod 때문에)
   - 노드별로 사용할 수 있는 가용 Secondary IP 중에 하나를 Pod에게 할당 했음
  
4) Pod 3도 마찬가지로 신규 Pod 생성에 따라 Slot과 ENI를 검토
   - 노드 3은 Sacondary ENI가 없음 (신규 Pod가 없었기 때문에 Primary ENI만 있었음)
   - Secondary ENI를 생성하는 작업을 수행 -> L-IPAM의 Warm Pool 대역에서 가용한 IP로 채워넣음
   - 그래서 노드3도 Primary ENI인 eth0과 Secondary ENI인 eth1이 생성됨.




















